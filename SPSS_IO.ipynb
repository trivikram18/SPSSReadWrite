{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing SPSS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import savReaderWriter as s\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading an SPSS dataset and create a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = s.SavReader('customer_dbase.sav', ioUtf8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = reader.all()\n",
    "Var_Names = reader.varNames\n",
    "Value_Labels = reader.valueLabels\n",
    "Variable_Labels = reader.varLabels\n",
    "Measure_Levels = reader.measureLevels\n",
    "Variable_Formats = reader.formats\n",
    "Missing_Values = reader.missingValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 132 entries, custid to response_03\n",
      "dtypes: float64(130), object(2)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "Index(['custid', 'region', 'townsize', 'gender', 'age', 'agecat', 'birthmonth',\n",
      "       'ed', 'edcat', 'jobcat',\n",
      "       ...\n",
      "       'owncd', 'ownpda', 'ownpc', 'ownipod', 'owngame', 'ownfax', 'news',\n",
      "       'response_01', 'response_02', 'response_03'],\n",
      "      dtype='object', length=132)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>region</th>\n",
       "      <th>townsize</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>agecat</th>\n",
       "      <th>birthmonth</th>\n",
       "      <th>ed</th>\n",
       "      <th>edcat</th>\n",
       "      <th>jobcat</th>\n",
       "      <th>...</th>\n",
       "      <th>owncd</th>\n",
       "      <th>ownpda</th>\n",
       "      <th>ownpc</th>\n",
       "      <th>ownipod</th>\n",
       "      <th>owngame</th>\n",
       "      <th>ownfax</th>\n",
       "      <th>news</th>\n",
       "      <th>response_01</th>\n",
       "      <th>response_02</th>\n",
       "      <th>response_03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3964-QJWTRG-NPN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>September</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0648-AIPJSP-UVM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>May</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5195-TLUDJE-HVO</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>June</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4459-VLPQUH-3OL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>May</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8158-SMTQFB-CNO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>July</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            custid  region  townsize  gender   age  agecat birthmonth    ed  \\\n",
       "0  3964-QJWTRG-NPN     1.0       2.0     1.0  20.0     2.0  September  15.0   \n",
       "1  0648-AIPJSP-UVM     5.0       5.0     0.0  22.0     2.0        May  17.0   \n",
       "2  5195-TLUDJE-HVO     3.0       4.0     1.0  67.0     6.0       June  14.0   \n",
       "3  4459-VLPQUH-3OL     4.0       3.0     0.0  23.0     2.0        May  16.0   \n",
       "4  8158-SMTQFB-CNO     2.0       2.0     0.0  26.0     3.0       July  16.0   \n",
       "\n",
       "   edcat  jobcat  ...  owncd  ownpda  ownpc  ownipod  owngame  ownfax  news  \\\n",
       "0    3.0     1.0  ...    0.0     0.0    0.0      1.0      1.0     0.0   0.0   \n",
       "1    4.0     2.0  ...    1.0     1.0    1.0      1.0      1.0     1.0   1.0   \n",
       "2    2.0     2.0  ...    1.0     0.0    0.0      0.0      0.0     0.0   1.0   \n",
       "3    3.0     2.0  ...    1.0     0.0    1.0      1.0      1.0     0.0   1.0   \n",
       "4    3.0     2.0  ...    1.0     0.0    1.0      0.0      1.0     0.0   0.0   \n",
       "\n",
       "   response_01  response_02  response_03  \n",
       "0          0.0          1.0          0.0  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          1.0          0.0          0.0  \n",
       "4          0.0          1.0          0.0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=all_data, columns=Var_Names)\n",
    "print(df.info())\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['custid', 'region', 'townsize', 'gender', 'age']\n",
      "<class 'dict'>\n",
      "{'custid': 'Customer ID', 'region': 'Geographic indicator', 'townsize': 'Size of hometown', 'gender': 'Gender', 'age': 'Age in years'}\n",
      "<class 'dict'>\n",
      "{'region': {1.0: 'Zone 1', 2.0: 'Zone 2', 3.0: 'Zone 3', 4.0: 'Zone 4', 5.0: 'Zone 5'}, 'townsize': {1.0: '> 250,000', 2.0: '50,000-249,999', 3.0: '10,000-49,999', 4.0: '2,500-9,999', 5.0: '< 2,500'}, 'gender': {0.0: 'Male', 1.0: 'Female'}, 'agecat': {1.0: '<18', 2.0: '18-24', 3.0: '25-34', 4.0: '35-49', 5.0: '50-64', 6.0: '>65', 9.0: 'No response'}, 'edcat': {1.0: 'Did not complete high school', 2.0: 'High school degree', 3.0: 'Some college', 4.0: 'College degree', 5.0: 'Post-undergraduate degree'}}\n",
      "<class 'dict'>\n",
      "{'custid': 'nominal', 'region': 'nominal', 'townsize': 'ordinal', 'gender': 'nominal', 'age': 'ratio'}\n",
      "<class 'dict'>\n",
      "{'custid': 'A15', 'region': 'F4', 'townsize': 'F4', 'gender': 'F4', 'age': 'F4'}\n",
      "<class 'dict'>\n",
      "{'custid': {}, 'region': {}, 'townsize': {}, 'gender': {}, 'age': {}}\n"
     ]
    }
   ],
   "source": [
    "print(type(Var_Names))\n",
    "print(Var_Names[0:5])\n",
    "\n",
    "print(type(Variable_Labels))\n",
    "print({k: Variable_Labels[k] for k in list(Variable_Labels)[0:5]})\n",
    "\n",
    "print(type(Value_Labels))\n",
    "print({k: Value_Labels[k] for k in list(Value_Labels)[0:5]})\n",
    "\n",
    "print(type(Measure_Levels))\n",
    "print({k: Measure_Levels[k] for k in list(Measure_Levels)[0:5]})\n",
    "\n",
    "print(type(Variable_Formats))\n",
    "print({k: Variable_Formats[k] for k in list(Variable_Formats)[0:5]})\n",
    "\n",
    "print(type(Missing_Values))\n",
    "print({k: Missing_Values[k] for k in list(Missing_Values)[0:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read the SPSS Dataset and Return the Pandas Dataframe and other SPSS meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadSPSS(sFileName):\n",
    "    \"\"\" This function reads in an SPSS file and prints quick info of the dataset.\n",
    "    Args:\n",
    "    \tSPSS Dataset name including the path\n",
    "    Returns:\n",
    "    \tDataframe\n",
    "    \tVariable Lables as a dictionary\n",
    "    \tValue Labels as a dictionary\n",
    "    \"\"\"\n",
    "    reader = s.SavReader(sFileName, ioUtf8=True)\n",
    "    all_data = reader.all()\n",
    "    Var_Names = reader.varNames\n",
    "    Variable_Labels = reader.varLabels\n",
    "    Value_Labels = reader.valueLabels\n",
    "    Measure_Levels = reader.measureLevels\n",
    "    Variable_Formats = reader.formats\n",
    "    Missing_Values = reader.missingValues\n",
    "    reader.close()\n",
    "    df = pd.DataFrame(data=all_data, columns=Var_Names)\n",
    "    print (f'Dataset Info:-\\nNo. of Records: {df.shape[0]}\\nNo. of Variables: {df.shape[1]}\\nNo. of Variable Labels: {len(Variable_Labels)}\\nNo. of Value Labels: {len(Value_Labels)}')\n",
    "    return df, Variable_Labels, Value_Labels, Measure_Levels, Variable_Formats, Missing_Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:-\n",
      "No. of Records: 5000\n",
      "No. of Variables: 132\n",
      "No. of Variable Labels: 132\n",
      "No. of Value Labels: 80\n"
     ]
    }
   ],
   "source": [
    "df_custDB, variable_labels_custDB, value_labels_custDB, measure_levels_custDB, variable_formats_custDB, missing_values_custDB = ReadSPSS('customer_dbase.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custDB.to_csv('Customer_dbase_ExportFromPandas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custid       object\n",
      "region      float64\n",
      "townsize    float64\n",
      "gender      float64\n",
      "age         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_custDB.dtypes[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the variable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintSPSSVariableInfo(df, varName):\n",
    "    print(f\"Variable info for '{varName}':\")\n",
    "    print(\"Variable Datatype: \", df[varName].dtype)\n",
    "    print(\"Variable Label: \", Variable_Labels[varName])\n",
    "    print(\"Value Label: \", Value_Labels[varName])\n",
    "    print(\"Measure Level: \", Measure_Levels[varName])\n",
    "    print(\"Variable Format: \", Variable_Formats[varName])\n",
    "    print(\"Missing Values: \", Missing_Values[varName])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable info for 'region':\n",
      "Variable Datatype:  float64\n",
      "Variable Label:  Geographic indicator\n",
      "Value Label:  {1.0: 'Zone 1', 2.0: 'Zone 2', 3.0: 'Zone 3', 4.0: 'Zone 4', 5.0: 'Zone 5'}\n",
      "Measure Level:  nominal\n",
      "Variable Format:  F4\n",
      "Missing Values:  {}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PrintSPSSVariableInfo(df_custDB, 'region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print frequencies of a variable with value labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValueCountsVL(df, sVariable, dictValueLabels, dictVariableLabels, bVariableLabelsRequired=True):\n",
    "    if bVariableLabelsRequired == True and sVariable in dictValueLabels:\n",
    "        print (dictVariableLabels[sVariable], \":\")\n",
    "        print (df[sVariable].replace(dictValueLabels[sVariable]).value_counts(dropna=False), \"\\n\")\n",
    "    else:\n",
    "        print (dictVariableLabels[sVariable], \":\")\n",
    "        print (df[sVariable].value_counts(dropna=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic indicator :\n",
      "Zone 5    1052\n",
      "Zone 1    1019\n",
      "Zone 2    1005\n",
      "Zone 3     981\n",
      "Zone 4     943\n",
      "Name: region, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ValueCountsVL(df_custDB, 'region', value_labels_custDB, variable_labels_custDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AppendCodesWithValueLabels(input_value_labels):\n",
    "    output_value_labels = {}\n",
    "    for di_keys, di_values in input_value_labels.items():\n",
    "        output_value_labels[di_keys] = {k: str(int(k)) + ' ' + str(v) for k, v in input_value_labels[di_keys].items()}\n",
    "    return output_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_labels_custDB_append = AppendCodesWithValueLabels(value_labels_custDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Labels Before:\n",
      "{'region': {1.0: 'Zone 1', 2.0: 'Zone 2', 3.0: 'Zone 3', 4.0: 'Zone 4', 5.0: 'Zone 5'}}\n",
      "\n",
      "Value Labels After Appending:\n",
      "{'region': {1.0: '1 Zone 1', 2.0: '2 Zone 2', 3.0: '3 Zone 3', 4.0: '4 Zone 4', 5.0: '5 Zone 5'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Value Labels Before:\")\n",
    "print({k: value_labels_custDB[k] for k in list(value_labels_custDB)[0:1]})\n",
    "print()\n",
    "print(\"Value Labels After Appending:\")\n",
    "print({k: value_labels_custDB_append[k] for k in list(value_labels_custDB_append)[0:1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateSPSSDatasetInfo(df, variable_labels, var=''):\n",
    "    \"\"\" This function gives variable description of dataframe.\n",
    "    Args:\n",
    "    \tDataframe, Variable Labels, and an optional group by varible passed as a list\n",
    "    Returns:\n",
    "    \tDataframe with variable description of the input dataframe\n",
    "    \"\"\"\n",
    "    if var == '':\n",
    "        df_var_description = pd.concat([df.describe().T,df.select_dtypes(include = 'object').describe().T], axis=0, sort=False)\n",
    "        df_var_labels = pd.DataFrame.from_dict({k: variable_labels[k] for k in df.columns}, orient='index')\n",
    "        df_var_description_with_variable_labels = pd.concat([df_var_description, df_var_labels], axis=1, sort=False)\n",
    "    else:\n",
    "        df_group = df.groupby(var)\n",
    "        df_var_description_numeric = df_group[df.columns].apply(lambda x: x.describe().T)\n",
    "        df_var_description_object = df_group[df.select_dtypes(include = 'object').columns].apply(lambda x: x.describe().T)\n",
    "        df_var_description = pd.concat([df_var_description_numeric, df_var_description_object], axis=0, sort=False)\n",
    "        df_var_description.reset_index(inplace=True)\n",
    "        df_var_labels = pd.DataFrame.from_dict({k: variable_labels[k] for k in df.columns}, orient='index')\n",
    "        df_var_labels.reset_index(inplace=True)\n",
    "        merge_variable = 'level_' + str(len(var))\n",
    "        df_var_description_with_variable_labels = df_var_description.merge(df_var_labels, how='left', left_on=merge_variable, right_on='index')\n",
    "        df_var_description_with_variable_labels.drop(columns=['index'], inplace=True)\n",
    "    return df_var_description_with_variable_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>5000</td>\n",
       "      <td>3.000800</td>\n",
       "      <td>1.430667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geographic indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>townsize</th>\n",
       "      <td>4998</td>\n",
       "      <td>2.691477</td>\n",
       "      <td>1.427611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Size of hometown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>5000</td>\n",
       "      <td>46.939800</td>\n",
       "      <td>17.703312</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age in years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agecat</th>\n",
       "      <td>5000</td>\n",
       "      <td>4.232200</td>\n",
       "      <td>1.303159</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age category</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count       mean        std   min   25%   50%   75%   max unique  \\\n",
       "region    5000   3.000800   1.430667   1.0   2.0   3.0   4.0   5.0    NaN   \n",
       "townsize  4998   2.691477   1.427611   1.0   1.0   3.0   4.0   5.0    NaN   \n",
       "gender    5000   0.510200   0.499946   0.0   0.0   1.0   1.0   1.0    NaN   \n",
       "age       5000  46.939800  17.703312  18.0  32.0  46.0  62.0  79.0    NaN   \n",
       "agecat    5000   4.232200   1.303159   2.0   3.0   4.0   5.0   6.0    NaN   \n",
       "\n",
       "          top freq                     0  \n",
       "region    NaN  NaN  Geographic indicator  \n",
       "townsize  NaN  NaN      Size of hometown  \n",
       "gender    NaN  NaN                Gender  \n",
       "age       NaN  NaN          Age in years  \n",
       "agecat    NaN  NaN          Age category  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_custDB_info = GenerateSPSSDatasetInfo(df_custDB, variable_labels_custDB)\n",
    "df_custDB_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custDB_info.to_csv('Customer_dbase_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate variable frequencies SPSS style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqAll(df, dictValueLabels, decimal_rounding=2, bVariableLabelsRequired=True):\n",
    "    \"\"\" This function generates frequencies of all the variables in a dataset.\n",
    "    Version: 2.0\n",
    "    Args:\n",
    "        Data frame name\n",
    "        Value Labels as dictionary\n",
    "        Optional decimal rounding. Default: 2\n",
    "    Returns:\n",
    "        A list of dataframes. Each dataframe is a frequency of the variable in the dataframe supplied\n",
    "    \"\"\"\n",
    "    if bVariableLabelsRequired == True:\n",
    "        x_1 = [pd.DataFrame(df[var].replace(dictValueLabels[var]).value_counts()) for var in df.columns if var in dictValueLabels]\n",
    "        x_2 = [pd.DataFrame(df[var].value_counts()) for var in df.columns if var not in dictValueLabels]\n",
    "        x = x_1 + x_2\n",
    "    else:\n",
    "        x = [pd.DataFrame(df[var].value_counts()) for var in df.columns]\n",
    "    for dff in x:\n",
    "        Total_Valid = dff.iloc[:,0].sum()\n",
    "        if df.shape[0] - Total_Valid  > 0:\n",
    "            dff.loc['Total Valid'] = Total_Valid\n",
    "            dff.loc['Missing'] = df.shape[0] - Total_Valid\n",
    "            dff.loc['Total'] = dff.iloc[:,0].sum() - Total_Valid\n",
    "        else:\n",
    "            dff.loc['Total'] = dff.iloc[:,0].sum()\n",
    "        dff['Percent'] = round((dff.iloc[:,0]/ df.shape[0])*100, decimal_rounding)\n",
    "        dff['Valid Percent'] = round((dff.iloc[:,0]/ Total_Valid)*100, decimal_rounding)\n",
    "        if df.shape[0] - Total_Valid  > 0:\n",
    "            dff.loc['Missing', 'Valid Percent'] = np.nan\n",
    "        dff.loc['Total', 'Valid Percent'] = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custDB_frequencies = freqAll(df_custDB, value_labels_custDB_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          region  Percent  Valid Percent\n",
       " 5 Zone 5    1052    21.04          21.04\n",
       " 1 Zone 1    1019    20.38          20.38\n",
       " 2 Zone 2    1005    20.10          20.10\n",
       " 3 Zone 3     981    19.62          19.62\n",
       " 4 Zone 4     943    18.86          18.86\n",
       " Total       5000   100.00            NaN,\n",
       "                   townsize  Percent  Valid Percent\n",
       " 1 > 250,000           1430    28.60          28.61\n",
       " 2 50,000-249,999      1055    21.10          21.11\n",
       " 3 10,000-49,999        896    17.92          17.93\n",
       " 4 2,500-9,999          861    17.22          17.23\n",
       " 5 < 2,500              756    15.12          15.13\n",
       " Total Valid           4998    99.96         100.00\n",
       " Missing                  2     0.04            NaN\n",
       " Total                 5000   100.00            NaN]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_custDB_frequencies[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate variable frequencies SPSS style and export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPSSfreqAll2csv(df, dictValueLabels, dictVariableLabels, fileName, decimal_rounding=2, bVariableLabelsRequired=True):\n",
    "    \"\"\" This function reads in a dataframe and generates/writes SPSS equivalent frequencies to a CVS file.\n",
    "    Version: 3.0\n",
    "    Args:\n",
    "    \tDataframe name\n",
    "        Value Labels as dictionary\n",
    "        Variable Labels as dictionary\n",
    "        CSV file name along with path\n",
    "        Optional decimal rounding. Default: 2\n",
    "    Returns:\n",
    "    \tCSV file with SPSS equivalent frequencies\n",
    "    \"\"\"\n",
    "    if bVariableLabelsRequired == True:\n",
    "        x_1 = [pd.DataFrame(df[var].replace(dictValueLabels[var]).value_counts()) for var in df.columns if var in dictValueLabels]\n",
    "        x_2 = [pd.DataFrame(df[var].value_counts()) for var in df.columns if var not in dictValueLabels]\n",
    "        x = x_1 + x_2\n",
    "    else:\n",
    "        x = [pd.DataFrame(df[var].value_counts()) for var in df.columns]\n",
    "    f = open(fileName, 'a', encoding='utf_8_sig')\n",
    "    for dff in x:\n",
    "        Total_Valid = dff.iloc[:, 0].sum()\n",
    "        Var_Name = dff.columns[0]\n",
    "        dff.rename(columns={dff.columns[0]: 'Frequency'}, inplace=True)\n",
    "        if df.shape[0] - Total_Valid > 0:\n",
    "            dff.loc['Total Valid'] = Total_Valid\n",
    "            dff.loc['Missing'] = df.shape[0] - Total_Valid\n",
    "            dff.loc['Total'] = dff.iloc[:, 0].sum() - Total_Valid\n",
    "        else:\n",
    "            dff.loc['Total'] = dff.iloc[:, 0].sum()\n",
    "        dff['Percent'] = round((dff.iloc[:, 0]/ df.shape[0])*100, decimal_rounding)\n",
    "        dff['Valid Percent'] = round((dff.iloc[:, 0]/ Total_Valid)*100, decimal_rounding)\n",
    "        if df.shape[0] - Total_Valid > 0:\n",
    "            dff.loc['Missing', 'Valid Percent'] = np.nan\n",
    "        dff.loc['Total', 'Valid Percent'] = np.nan\n",
    "        f.write('\"' + Var_Name + ' ' + dictVariableLabels[Var_Name] + '\"' + \"\\n\")\n",
    "        dff.to_csv(f, line_terminator='\\n', encoding='utf_8_sig')\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPSSfreqAll2csv(df_custDB, value_labels_custDB_append, variable_labels_custDB, 'Customer_dbase_frequencies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing info of 2 datasets\n",
    "\n",
    "Often we need to compare 2 datasets which has same data in it, probably before and after some data operations. This function helps in comparing the data at variable informaton level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareDatasets(df1, df2, df1_variable_labels, df2_variable_labels, groupby_variable=''):\n",
    "    merge_variable = 'level_' + str(len(groupby_variable))\n",
    "    df1_description = GenerateSPSSDatasetInfo(df1, df1_variable_labels, groupby_variable)\n",
    "    df2_description = GenerateSPSSDatasetInfo(df2, df2_variable_labels, groupby_variable)\n",
    "\n",
    "    if groupby_variable != '':\n",
    "        df1_description.set_index(groupby_variable + [merge_variable], inplace=True)\n",
    "        df2_description.set_index(groupby_variable + [merge_variable], inplace=True)\n",
    "\n",
    "    df_final = df1_description.merge(df2_description, how='outer', left_index=True, right_index=True, suffixes=('_processed', '_raw'))\n",
    "\n",
    "    df_final['count_diff'] = df_final['count_processed'].fillna(0) - df_final['count_raw'].fillna(0)\n",
    "    df_final['mean_diff'] = df_final['mean_processed'].fillna(0) - df_final['mean_raw'].fillna(0)\n",
    "    df_final['freq_diff'] = df_final['freq_processed'].fillna(0) - df_final['freq_raw'].fillna(0)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ease I am just using the same datasets\n",
    "df_custDB_compare = compareDatasets(df_custDB, df_custDB, variable_labels_custDB, variable_labels_custDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_processed</th>\n",
       "      <th>mean_processed</th>\n",
       "      <th>std_processed</th>\n",
       "      <th>min_processed</th>\n",
       "      <th>25%_processed</th>\n",
       "      <th>50%_processed</th>\n",
       "      <th>75%_processed</th>\n",
       "      <th>max_processed</th>\n",
       "      <th>unique_processed</th>\n",
       "      <th>top_processed</th>\n",
       "      <th>...</th>\n",
       "      <th>50%_raw</th>\n",
       "      <th>75%_raw</th>\n",
       "      <th>max_raw</th>\n",
       "      <th>unique_raw</th>\n",
       "      <th>top_raw</th>\n",
       "      <th>freq_raw</th>\n",
       "      <th>0_raw</th>\n",
       "      <th>count_diff</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>freq_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>5000</td>\n",
       "      <td>3.000800</td>\n",
       "      <td>1.430667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geographic indicator</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>townsize</th>\n",
       "      <td>4998</td>\n",
       "      <td>2.691477</td>\n",
       "      <td>1.427611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Size of hometown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>5000</td>\n",
       "      <td>46.939800</td>\n",
       "      <td>17.703312</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age in years</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agecat</th>\n",
       "      <td>5000</td>\n",
       "      <td>4.232200</td>\n",
       "      <td>1.303159</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age category</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         count_processed  mean_processed  std_processed  min_processed  \\\n",
       "region              5000        3.000800       1.430667            1.0   \n",
       "townsize            4998        2.691477       1.427611            1.0   \n",
       "gender              5000        0.510200       0.499946            0.0   \n",
       "age                 5000       46.939800      17.703312           18.0   \n",
       "agecat              5000        4.232200       1.303159            2.0   \n",
       "\n",
       "          25%_processed  50%_processed  75%_processed  max_processed  \\\n",
       "region              2.0            3.0            4.0            5.0   \n",
       "townsize            1.0            3.0            4.0            5.0   \n",
       "gender              0.0            1.0            1.0            1.0   \n",
       "age                32.0           46.0           62.0           79.0   \n",
       "agecat              3.0            4.0            5.0            6.0   \n",
       "\n",
       "         unique_processed top_processed  ... 50%_raw 75%_raw max_raw  \\\n",
       "region                NaN           NaN  ...     3.0     4.0     5.0   \n",
       "townsize              NaN           NaN  ...     3.0     4.0     5.0   \n",
       "gender                NaN           NaN  ...     1.0     1.0     1.0   \n",
       "age                   NaN           NaN  ...    46.0    62.0    79.0   \n",
       "agecat                NaN           NaN  ...     4.0     5.0     6.0   \n",
       "\n",
       "          unique_raw  top_raw  freq_raw                 0_raw  count_diff  \\\n",
       "region           NaN      NaN       NaN  Geographic indicator         0.0   \n",
       "townsize         NaN      NaN       NaN      Size of hometown         0.0   \n",
       "gender           NaN      NaN       NaN                Gender         0.0   \n",
       "age              NaN      NaN       NaN          Age in years         0.0   \n",
       "agecat           NaN      NaN       NaN          Age category         0.0   \n",
       "\n",
       "          mean_diff  freq_diff  \n",
       "region          0.0          0  \n",
       "townsize        0.0          0  \n",
       "gender          0.0          0  \n",
       "age             0.0          0  \n",
       "agecat          0.0          0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_custDB_compare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing frequencies from 2 datasets\n",
    "\n",
    "Similar to above, at times we may need to compare the frequencies of 2 dataset to see the changes of before and after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets_frequencies(df_primary, df_secondary, value_labels_primary, variable_labels_primary, file_name):\n",
    "    \"\"\" This function generates and compares frequencies of the variables between 2 datasets.\n",
    "    It uses the variables, variable labels and value labels from the primary dataset as base.\n",
    "    Variables which are only in the secondary dataset are ignored\n",
    "    Version: 1.0\n",
    "    Args:\n",
    "        Primary Data frame name\n",
    "        Secondary Data frame name\n",
    "        Value Labels as dictionary - Primary dataset\n",
    "        Variable Labels as dictionary - Primary dataset\n",
    "        CSV file name along with path\n",
    "    Returns:\n",
    "    \tCSV file with SPSS equivalent frequencies compared between 2 datasets\n",
    "    \"\"\"\n",
    "    freq_primary = freqAll(df_primary, value_labels_primary)\n",
    "    freq_secondary = freqAll(df_secondary[df_primary.columns], value_labels_primary)\n",
    "    freq_all = [pd.DataFrame(freq_primary[var]).merge(pd.DataFrame(freq_secondary[var]), \n",
    "                             how='outer', \n",
    "                             left_index=True, right_index=True,\n",
    "                             suffixes=('_processed', '_raw')) for var in range(len(freq_primary))]\n",
    "    f = open(file_name,'a', encoding='utf_8_sig')\n",
    "    for df in freq_all:\n",
    "        df['Diff_Frequency'] = df.iloc[:,0] - df.iloc[:,3]\n",
    "        df['Diff_Percent'] = df.iloc[:,1] - df.iloc[:,4]\n",
    "        df['Diff_Valid_Percent'] = df.iloc[:,2] - df.iloc[:,5]\n",
    "        f.write('\"' + df.columns[0].replace('_processed', '') + ' ' + df.columns[0].replace(df.columns[0], variable_labels_primary[df.columns[0].replace('_processed', '')]) + '\"' + \"\\n\")\n",
    "        df.rename(columns={df.columns[0]: 'Frequency_processed', df.columns[3]: 'Frequency_raw'}, inplace=True)\n",
    "        df.to_csv(f, line_terminator='\\n', encoding='utf_8_sig')\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_datasets_frequencies(df_custDB, df_custDB, value_labels_custDB, variable_labels_custDB, 'Customer_dbase_frequencies_compare.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to an SPSS dataset from a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate all the parameters first\n",
    "savFileName = 'TestSAV.sav'\n",
    "varNames = ['custid', 'region', 'gender']\n",
    "records = df[['custid', 'region', 'gender']].values\n",
    "varTypes = {'custid':15, 'region':0, 'gender':0}\n",
    "varLabels = {x:Variable_Labels[x] for x in ['custid', 'region', 'gender']}\n",
    "valueLabels = {x:Value_Labels[x] for x in ['region', 'gender']}\n",
    "measureLevels = {x:Measure_Levels[x] for x in ['custid', 'region', 'gender']}\n",
    "formats = {x:Variable_Formats[x] for x in ['custid', 'region', 'gender']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parameters and write the sav file\n",
    "with s.SavWriter(savFileName, varNames, varTypes, \n",
    "                 varLabels=varLabels, \n",
    "                 valueLabels=valueLabels, \n",
    "                 measureLevels = measureLevels, \n",
    "                 formats = formats,\n",
    "                 ioUtf8=True) as writer:\n",
    "    for record in records:\n",
    "        writer.writerow(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
